{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy = True\n",
    "#System\n",
    "import time\n",
    "import re\n",
    "import itertools\n",
    "import string\n",
    "#processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "#feature engineering\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn_pandas import DataFrameMapper, cross_val_score\n",
    "\n",
    "#classifiers\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, SGDClassifier, Perceptron, RidgeClassifierCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "#Evaluation\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, fbeta_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Report\n",
    "import matplotlib.pyplot as plt   \n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "dataFrameTraining = pd.read_csv(\"data/Toxic_train_set.csv\")\n",
    "dataFrameTesting = pd.read_csv(\"data/Toxic_test_set.csv\")\n",
    "\n",
    "dftr = dataFrameTraining\n",
    "dfte = dataFrameTesting\n",
    "\n",
    "all_categories = [\"obscene\", \"threat\", \"insult\", \"hate\", \"Intolerant\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([dftr, dfte], ignore_index=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = nltk.corpus.stopwords.words('english')\n",
    "new_stop_words = ['?','!',',','.',';','&','>','<',')','(','/','\\'s','\\'\\'','``']\n",
    "stopWords.extend(new_stop_words)\n",
    "new_stop_words_1 = ['I','thi','He','We','hi','everi','like','boy','march']\n",
    "stopWords.extend(new_stop_words_1)\n",
    "\n",
    "ps = nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for countvectorizer\n",
    "def comment_clean_cv(comment):\n",
    "    comment = \"\".join([word.lower() for word in comment if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', comment)\n",
    "    comment = [ps.stem(word) for word in tokens if word not in stopWords]\n",
    "    return comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['comment_length'] = data['Comments'].apply(lambda x: len(x) - x.count(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polarityReturn(text):    \n",
    "    try:\n",
    "        return TextBlob(text).sentiment.polarity\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['sentiment'] = data['Comments'].apply(polarityReturn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "def polarityReturn(text):    \n",
    "    try:\n",
    "        return TextBlob(text).sentiment.polarity\n",
    "    except:\n",
    "        return None\n",
    "# adding new feature of sentiment polarity rating\n",
    "data['sentiment'] = data['Comments'].apply(polarityReturn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabelList(data):\n",
    "    categories = []\n",
    "    for i in range(len(data)):            \n",
    "        tempList = []\n",
    "        for category in all_categories:        \n",
    "            if data[category][i] == 1:\n",
    "                tempList.append(category)   \n",
    "        #print(tempList, i)\n",
    "                #print(data[category][i], category, i)            \n",
    "        categories.append(tempList)\n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making labels single list\n",
    "train_categories = tuple(getLabelList(dftr))\n",
    "test_categories = tuple(getLabelList(dfte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_categories + test_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents = tuple(data['Comments'])\n",
    "def tf_idf(docs):\n",
    "    tfidf = TfidfVectorizer(tokenizer=comment_clean_cv, max_features=105, use_idf=True, sublinear_tf=True)\n",
    "    tfidf.fit(docs)\n",
    "    return tfidf\n",
    "representer = tf_idf(train_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "target = mlb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmFeatures = DataFrameMapper([    \n",
    "    ('Comments', representer),\n",
    "    ('comment_length', None),\n",
    "    ('sentiment', None)\n",
    "])\n",
    "features = dfmFeatures.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(features, target, test_size=0.3, train_size=0.7, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    ('DecisionTreeClassifier', OneVsRestClassifier(DecisionTreeClassifier())),\n",
    "    ('LinearSVC', OneVsRestClassifier(LinearSVC(random_state=23))),        \n",
    "    ('LogisticRegression', OneVsRestClassifier(LogisticRegression())),    \n",
    "    ('LogisticRegressionCV', OneVsRestClassifier(LogisticRegressionCV())),\n",
    "    ('SGDClassifier', OneVsRestClassifier(SGDClassifier())),\n",
    "    ('Perceptron', OneVsRestClassifier(Perceptron())),\n",
    "    ('RidgeClassifierCV', OneVsRestClassifier(RidgeClassifierCV())),\n",
    "    ('RandomForestClassifier', OneVsRestClassifier(RandomForestClassifier(n_estimators=100, n_jobs=10))),        \n",
    "    ('AdaBoostClassifier', OneVsRestClassifier(AdaBoostClassifier())),    \n",
    "    ('ExtraTreesClassifier', OneVsRestClassifier(ExtraTreesClassifier())),        \n",
    "    ('KNeighborsClassifier', OneVsRestClassifier(KNeighborsClassifier(n_neighbors=5))),    \n",
    "    ('MLPClassifier', OneVsRestClassifier(MLPClassifier())),    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier                    : score  in train /  test\n",
      "--------------------------------------------------------------------------------\n",
      "DecisionTreeClassifier        : 80.33% 92.87% in 0.02s train / 0.00s test\n",
      "LinearSVC                     : 75.41% 86.62% in 0.07s train / 0.00s test\n",
      "LogisticRegression            : 49.18% 75.74% in 0.02s train / 0.00s test\n",
      "LogisticRegressionCV          : 85.25% 93.39% in 5.73s train / 0.00s test\n",
      "SGDClassifier                 : 0.00% 45.19% in 0.02s train / 0.00s test\n",
      "Perceptron                    : 0.00% 29.37% in 0.02s train / 0.00s test\n",
      "RidgeClassifierCV             : 88.52% 94.45% in 0.05s train / 0.00s test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subash\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\subash\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\subash\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\subash\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\subash\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\subash\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\subash\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\subash\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\subash\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\subash\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\subash\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\subash\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier        : 78.69% 91.22% in 1.63s train / 0.57s test\n",
      "AdaBoostClassifier            : 93.44% 97.71% in 0.68s train / 0.04s test\n",
      "ExtraTreesClassifier          : 75.41% 90.02% in 0.11s train / 0.01s test\n",
      "KNeighborsClassifier          : 13.11% 38.87% in 0.01s train / 0.01s test\n",
      "MLPClassifier                 : 3.28% 24.30% in 0.69s train / 0.00s test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subash\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\subash\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print((\"{clf_name:<30}: {score:<5}  in {train_time:>5} /  {test_time}\")\n",
    "      .format(clf_name=\"Classifier\", score=\"score\", train_time=\"train\", test_time=\"test\"))\n",
    "print(\"-\" * 80)\n",
    "cls_dict = {}\n",
    "for clf_name, classifier in classifiers:\n",
    "    t0 = time.time()\n",
    "    y_pred = classifier.fit(X_train, Y_train)\n",
    "    cls_dict.update({clf_name: y_pred})\n",
    "    t1 = time.time()\n",
    "    \n",
    "    preds = classifier.predict(X_test)\n",
    "    preds[preds >= 0.5] = 1\n",
    "    preds[preds < 0.5] = 0    \n",
    "    t2 = time.time()\n",
    "\n",
    "    acc = accuracy_score(y_true=Y_test, y_pred=preds)\n",
    "    f1 = fbeta_score(y_true=Y_test, y_pred=preds, beta=1, average=\"weighted\")\n",
    "    print((\"{clf_name:<30}: {acc:0.2f}% {f1:0.2f}% in {train_time:0.2f}s\"\n",
    "           \" train / {test_time:0.2f}s test\")\n",
    "          .format(clf_name=clf_name,\n",
    "                  acc=(acc * 100),\n",
    "                  f1=(f1 * 100),\n",
    "                  train_time=t1 - t0,\n",
    "                  test_time=t2 - t1))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7540983606557377, Precision: 0.8114754098360656,Recall: 0.7950819672131147, F1: 0.7950819672131147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\subash\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\subash\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "Y_test_predict = cls_dict['LinearSVC'].predict(X_test)\n",
    "\n",
    "[precision, recall, F1, support] = \\\n",
    "precision_recall_fscore_support(Y_test, Y_test_predict, average='samples')\n",
    "accuracy = accuracy_score(Y_test, Y_test_predict)\n",
    "print(\"Accuracy: {}, Precision: {},Recall: {}, F1: {}\".format(accuracy, precision, recall, F1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
